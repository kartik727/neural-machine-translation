{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "seq2seq-attention.ipynb",
      "provenance": [],
      "toc_visible": true,
      "mount_file_id": "https://github.com/kartik727/neural-machine-translation/blob/master/Seq2Seq_with_attention.ipynb",
      "authorship_tag": "ABX9TyPJ981O1HfiAY0YAFpjfNf5",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/kartik727/neural-machine-translation/blob/master/Seq2Seq_with_attention.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h9w8BVLFXfjP"
      },
      "source": [
        "# Seq2Seq with attention\n",
        "\n",
        "## Dependencies\n",
        "Primary library used for modelling and training - trax\n",
        "\n",
        "## Data - Tensorflow Datasets (TFDS)\n",
        "1. OPUS (`'opus'`)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nIxeipWjVbKF"
      },
      "source": [
        "import random\n",
        "import numpy as np\n",
        "import re\n",
        "from collections import defaultdict\n",
        "import os\n",
        "import time\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.ticker as ticker\n",
        "import shutil\n",
        "from tqdm import tqdm, trange\n",
        "\n",
        "import nltk\n",
        "import tensorflow as tf\n",
        "import tensorflow_datasets as tfds"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vYIN8QK51Fr4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "394e760c-dc58-4650-b715-abdc522e78e4"
      },
      "source": [
        "# Utils\n",
        "\n",
        "!git clone https://gist.github.com/c47d0ad11b63acd334e760fc4ed21488.git namespace\n",
        "!git clone https://gist.github.com/553d2d565a17788d6217eba65e770c41.git tb_logger"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "fatal: destination path 'namespace' already exists and is not an empty directory.\n",
            "fatal: destination path 'tb_logger' already exists and is not an empty directory.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KqG3uKccP1t7"
      },
      "source": [
        "from namespace.namespace import Namespace\n",
        "from tb_logger.tensorboard_logger_2 import Logger as TB_Logger"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oe2lkV32ruUS"
      },
      "source": [
        "config_dict = {\n",
        "    'model' : {\n",
        "        'embedding_size' : 256,\n",
        "        'n_encoder_layers' : 1,\n",
        "        'n_decoder_layers' : 1,\n",
        "        'n_attention_heads' : 1,\n",
        "        'attention_dropout' : 0.,\n",
        "        'n_units' : 1024,\n",
        "        'batch_size' : 32,\n",
        "        'recurrent_cell' : 'LSTM'\n",
        "    },\n",
        "    'languages' : {\n",
        "        'input' : {\n",
        "            'name' : 'en',\n",
        "            'sentence_maxlen' : 30,\n",
        "            'vocab_size' : 20_000,\n",
        "        },\n",
        "        'target' : {\n",
        "            'name' : 'de',\n",
        "            'sentence_maxlen' : 30,\n",
        "            'vocab_size' : 20_000,\n",
        "        }\n",
        "    },\n",
        "    'data' : {\n",
        "        'dataset_name' : 'opus',\n",
        "        'load_pcnt' : 20,\n",
        "        'shuffle' : True\n",
        "    },\n",
        "    'preprocessing' : {\n",
        "        'start_token' : '<start>',\n",
        "        'end_token' : '<end>',\n",
        "        'oov_token' : '<unk>',\n",
        "        'padding' : 'post',\n",
        "        'tokenizer_fit_pcnt' : 30\n",
        "    },\n",
        "    'training' : {\n",
        "        'epochs' : 1\n",
        "    },\n",
        "    'logging' : {\n",
        "        'dir' : '/content/out/tensorboard/logs/',\n",
        "        'name' : 'seq2seq machine translation',\n",
        "        'description' : 'NMT using seq2seq model with attention'\n",
        "    }\n",
        "}\n",
        "\n",
        "config = Namespace(**config_dict)"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TFkyOppErvHW",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5e455286-3ada-4426-a18f-97860fee76f3"
      },
      "source": [
        "device_name = tf.test.gpu_device_name()\n",
        "if device_name != '/device:GPU:0':\n",
        "    print('GPU device not found')\n",
        "else:\n",
        "    print('Found GPU at: {}'.format(device_name))"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found GPU at: /device:GPU:0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5kmVeEd_NRgw",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7000e6e3-6dc1-48dd-ee9e-08761f7fa428"
      },
      "source": [
        "try:\n",
        "  tpu = tf.distribute.cluster_resolver.TPUClusterResolver()  # TPU detection\n",
        "  print('Running on TPU ', tpu.cluster_spec().as_dict()['worker'])\n",
        "except ValueError:\n",
        "  print('Not connected to a TPU runtime')"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Not connected to a TPU runtime\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5iypoagmSh3e"
      },
      "source": [
        "logger = TB_Logger(config.logging.dir)"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WWGQout8gG-H"
      },
      "source": [
        "dataset_train = tfds.load(config.data.dataset_name, split=f'train[:{config.data.load_pcnt}%]', batch_size=-1, shuffle_files=config.data.shuffle)\n",
        "ds_np = tfds.as_numpy(dataset_train)"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_0zG3MIS_1LB"
      },
      "source": [
        "class DataGenerator(tf.keras.utils.Sequence):\n",
        "    link = 'https://stanford.edu/~shervine/blog/keras-how-to-generate-data-on-the-fly'\n",
        "    def __init__(self, file_locs, batch_size, shuffle=True):\n",
        "        self.file_locs = file_locs\n",
        "        self.batch_size = batch_size\n",
        "        self.shuffle = shuffle\n",
        "        \n",
        "        self.on_epoch_end()\n",
        "        \n",
        "    def on_epoch_end(self):\n",
        "        '''\n",
        "        Performs end-of-epoch operations like shuffling data,\n",
        "        printing info etc.\n",
        "        '''\n",
        "        if self.shuffle == True:\n",
        "            self.metadata = shuffle(self.metadata)\n",
        "            \n",
        "    def __generate_data(self, batch_metadata):\n",
        "        df = pd.DataFrame(columns=['filename', 'X'])\n",
        "        \n",
        "        for i, r in batch_metadata.iterrows():\n",
        "            X_row = extract(self.file_locs[i], sr=self.sr)\n",
        "            df = df.append({'filename':i, 'X':X_row}, ignore_index=True)\n",
        "        \n",
        "        df.set_index('filename', drop=True, inplace=True)\n",
        "        df_batch = df.join(batch_metadata, how='inner')\n",
        "        self.df = df\n",
        "        self.df_batch = df_batch\n",
        "        \n",
        "        X_batch = np.stack(np.array(df_batch['X'])) # Workaround. Needs fix\n",
        "        \n",
        "        Y_batch_ = np.array(df_batch[self.label])\n",
        "        Y_batch_ = self.le.transform(Y_batch_)\n",
        "        Y_batch = Y_batch_ #tf.keras.utils.to_categorical(Y_batch_, num_classes=self.num_classes)\n",
        "        \n",
        "        return X_batch, Y_batch\n",
        "        \n",
        "    def __len__(self):\n",
        "        return int(np.floor(self.metadata.shape[0] / self.batch_size))\n",
        "    \n",
        "    def __getitem__(self, index):\n",
        "        batch_metadata = self.metadata.iloc[index*self.batch_size:(index+1)*self.batch_size, :]\n",
        "        return self.__generate_data(batch_metadata)"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f-dx2pyK-_LL"
      },
      "source": [
        "def preprocess_sentence(w, max_len):\n",
        "    w = w.decode().lower().strip()\n",
        "\n",
        "    # creating a space between a word and the punctuation following it\n",
        "    # eg: \"he is a boy.\" => \"he is a boy .\"\n",
        "    # Reference:- https://stackoverflow.com/questions/3645931/python-padding-punctuation-with-white-spaces-keeping-punctuation\n",
        "    w = re.sub(r\"([?.!,¿])\", r\" \\1 \", w)\n",
        "    w = re.sub(r'[\" \"]+', \" \", w)\n",
        "\n",
        "    # replacing everything with space except (a-z, A-Z, \".\", \"?\", \"!\", \",\")\n",
        "    w = re.sub(r\"[^a-zA-Z?.!,¿]+\", \" \", w)\n",
        "\n",
        "    w = w.strip()\n",
        "\n",
        "    w = ' '.join(w.split()[:max_len])\n",
        "\n",
        "    # adding a start and an end token to the sentence\n",
        "    # so that the model know when to start and stop predicting.\n",
        "    w = f'{config.preprocessing.start_token} {w} {config.preprocessing.end_token}'\n",
        "    return w"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fKqlJpudIBTD"
      },
      "source": [
        "def preprocess_data(data, max_len):\n",
        "    res = []\n",
        "    for sentence in data:\n",
        "        res.append(preprocess_sentence(sentence, max_len))\n",
        "    return np.array(res)"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3p0J-B6dGj9c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4b064f65-caa6-441c-d574-538a372863fe"
      },
      "source": [
        "lang_tokenizer = {}\n",
        "preprocessed_dataset = {}\n",
        "\n",
        "for lang in config.languages:\n",
        "    print(f'Preprocessing {lang.name}')\n",
        "    tokenizer = tf.keras.preprocessing.text.Tokenizer(\n",
        "        num_words=lang.vocab_size,\n",
        "        filters='',\n",
        "        oov_token=config.preprocessing.oov_token\n",
        "        )\n",
        "    preprocessed_data = preprocess_data(ds_np[lang.name], lang.sentence_maxlen)\n",
        "    tokenizer.fit_on_texts(preprocessed_data)\n",
        "    lang_tokenizer[lang.name] = tokenizer\n",
        "\n",
        "    tensor = tokenizer.texts_to_sequences(preprocessed_data)\n",
        "    tensor = tf.keras.preprocessing.sequence.pad_sequences(tensor, padding=config.preprocessing.padding)\n",
        "    preprocessed_dataset[lang.name] = tensor"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Preprocessing en\n",
            "Preprocessing de\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EyJI-cECVJMC"
      },
      "source": [
        "dataset = tf.data.Dataset.from_tensor_slices((\n",
        "    preprocessed_dataset[config.languages.input.name],\n",
        "    preprocessed_dataset[config.languages.target.name]\n",
        "    ))\n",
        "dataset = dataset.batch(config.model.batch_size, drop_remainder=True)"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5SZn3zpaV3pU"
      },
      "source": [
        "steps_per_epoch = len(dataset)\n",
        "\n",
        "vocab_input_size = len(lang_tokenizer[config.languages.input.name].word_index)+1\n",
        "vocab_target_size = len(lang_tokenizer[config.languages.target.name].word_index)+1"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jAat1xQtWSan",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4dde68c4-5725-4f91-9dc6-29974c1f1889"
      },
      "source": [
        "example_input_batch, example_target_batch = next(iter(dataset))\n",
        "example_input_batch.shape, example_target_batch.shape"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(TensorShape([32, 32]), TensorShape([32, 32]))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k6HeF0Mv8CRS"
      },
      "source": [
        "max_len_inp = preprocessed_dataset[config.languages.input.name].shape[1]\n",
        "max_len_targ = preprocessed_dataset[config.languages.target.name].shape[1]"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UJqs8KhXc76K"
      },
      "source": [
        "## Keras\n",
        "\n",
        "Source: [Tensorflow NMT tutorial](https://www.tensorflow.org/tutorials/text/nmt_with_attention)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PUt7-mIZc3Vz"
      },
      "source": [
        "class Encoder(tf.keras.Model):\n",
        "  def __init__(self, vocab_size, embedding_dim, enc_units, batch_sz):\n",
        "    super(Encoder, self).__init__()\n",
        "    self.batch_sz = batch_sz\n",
        "    self.enc_units = enc_units\n",
        "    self.embedding = tf.keras.layers.Embedding(vocab_size, embedding_dim)\n",
        "    self.gru = tf.keras.layers.GRU(self.enc_units,\n",
        "                                   return_sequences=True,\n",
        "                                   return_state=True,\n",
        "                                   recurrent_initializer='glorot_uniform')\n",
        "\n",
        "  def call(self, x, hidden):\n",
        "    x = self.embedding(x)\n",
        "    output, state = self.gru(x, initial_state=hidden)\n",
        "    return output, state\n",
        "\n",
        "  def initialize_hidden_state(self):\n",
        "    return tf.zeros((self.batch_sz, self.enc_units))"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DSmKsAw13NGd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "74e7970c-c88f-4bdd-f708-6d5e1e9c77f6"
      },
      "source": [
        "encoder = Encoder(vocab_input_size, config.model.embedding_size, config.model.n_units, config.model.batch_size)\n",
        "\n",
        "# sample input\n",
        "sample_hidden = encoder.initialize_hidden_state()\n",
        "sample_output, sample_hidden = encoder(example_input_batch, sample_hidden)\n",
        "print('Encoder output shape: (batch size, sequence length, units)', sample_output.shape)\n",
        "print('Encoder Hidden state shape: (batch size, units)', sample_hidden.shape)"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Encoder output shape: (batch size, sequence length, units) (32, 32, 1024)\n",
            "Encoder Hidden state shape: (batch size, units) (32, 1024)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3HadZkjkjVuj"
      },
      "source": [
        "class BahdanauAttention(tf.keras.layers.Layer):\n",
        "  def __init__(self, units):\n",
        "    super(BahdanauAttention, self).__init__()\n",
        "    self.W1 = tf.keras.layers.Dense(units)\n",
        "    self.W2 = tf.keras.layers.Dense(units)\n",
        "    self.V = tf.keras.layers.Dense(1)\n",
        "\n",
        "  def call(self, query, values):\n",
        "    # query hidden state shape == (batch_size, hidden size)\n",
        "    # query_with_time_axis shape == (batch_size, 1, hidden size)\n",
        "    # values shape == (batch_size, max_len, hidden size)\n",
        "    # we are doing this to broadcast addition along the time axis to calculate the score\n",
        "    query_with_time_axis = tf.expand_dims(query, 1)\n",
        "\n",
        "    # score shape == (batch_size, max_length, 1)\n",
        "    # we get 1 at the last axis because we are applying score to self.V\n",
        "    # the shape of the tensor before applying self.V is (batch_size, max_length, units)\n",
        "    score = self.V(tf.nn.tanh(\n",
        "        self.W1(query_with_time_axis) + self.W2(values)))\n",
        "\n",
        "    # attention_weights shape == (batch_size, max_length, 1)\n",
        "    attention_weights = tf.nn.softmax(score, axis=1)\n",
        "\n",
        "    # context_vector shape after sum == (batch_size, hidden_size)\n",
        "    context_vector = attention_weights * values\n",
        "    context_vector = tf.reduce_sum(context_vector, axis=1)\n",
        "\n",
        "    return context_vector, attention_weights"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c-kb7fComx3C",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "959cfa4d-8773-4ffa-8e64-5a9773d63511"
      },
      "source": [
        "attention_layer = BahdanauAttention(10)\n",
        "attention_result, attention_weights = attention_layer(sample_hidden, sample_output)\n",
        "\n",
        "print(\"Attention result shape: (batch size, units)\", attention_result.shape)\n",
        "print(\"Attention weights shape: (batch_size, sequence_length, 1)\", attention_weights.shape)"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Attention result shape: (batch size, units) (32, 1024)\n",
            "Attention weights shape: (batch_size, sequence_length, 1) (32, 32, 1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CVmRySLCmx0_"
      },
      "source": [
        "class Decoder(tf.keras.Model):\n",
        "  def __init__(self, recurrent_cell, vocab_size, embedding_dim, dec_units, batch_sz):\n",
        "    super(Decoder, self).__init__()\n",
        "    self.batch_sz = batch_sz\n",
        "    self.dec_units = dec_units\n",
        "    self.embedding = tf.keras.layers.Embedding(vocab_size, embedding_dim)\n",
        "    self.recurrent_cell = recurrent_cell\n",
        "    self.gru = tf.keras.layers.GRU(self.dec_units,\n",
        "                                   return_sequences=True,\n",
        "                                   return_state=True,\n",
        "                                   recurrent_initializer='glorot_uniform')\n",
        "    self.lstm = tf.keras.layers.LSTM(self.dec_units,\n",
        "                                     return_sequences=True,\n",
        "                                     return_state=True)\n",
        "    self.fc = tf.keras.layers.Dense(vocab_size)\n",
        "\n",
        "    # used for attention\n",
        "    self.attention = BahdanauAttention(self.dec_units)\n",
        "\n",
        "  def call(self, x, hidden, enc_output):\n",
        "    # enc_output shape == (batch_size, max_length, hidden_size)\n",
        "    context_vector, attention_weights = self.attention(hidden, enc_output)\n",
        "\n",
        "    # x shape after passing through embedding == (batch_size, 1, embedding_dim)\n",
        "    x = self.embedding(x)\n",
        "\n",
        "    # x shape after concatenation == (batch_size, 1, embedding_dim + hidden_size)\n",
        "    x = tf.concat([tf.expand_dims(context_vector, 1), x], axis=-1)\n",
        "\n",
        "    if self.recurrent_cell=='GRU':\n",
        "        # passing the concatenated vector to the GRU\n",
        "        output, state = self.gru(x)\n",
        "    elif self.recurrent_cell=='LSTM':\n",
        "        output, state, _ = self.lstm(x)\n",
        "    else:\n",
        "        raise Exception('Invalid recurrent cell')\n",
        "\n",
        "    # output shape == (batch_size * 1, hidden_size)\n",
        "    output = tf.reshape(output, (-1, output.shape[2]))\n",
        "\n",
        "    # output shape == (batch_size, vocab)\n",
        "    x = self.fc(output)\n",
        "\n",
        "    return x, state, attention_weights"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-gPNCU07mxy9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ff48e2ef-5e0a-4852-c98d-6bc05ce40160"
      },
      "source": [
        "decoder = Decoder(config.model.recurrent_cell, vocab_target_size, config.model.embedding_size, config.model.n_units, config.model.batch_size)\n",
        "\n",
        "sample_decoder_output, _, _ = decoder(tf.random.uniform((config.model.batch_size, 1)),\n",
        "                                      sample_hidden, sample_output)\n",
        "\n",
        "print('Decoder output shape: (batch_size, vocab size)', sample_decoder_output.shape)"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Decoder output shape: (batch_size, vocab size) (32, 43497)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8iJp1zO3mxxc"
      },
      "source": [
        "optimizer = tf.keras.optimizers.Adam()\n",
        "loss_object = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True,\n",
        "                                                            reduction='none')\n",
        "\n",
        "\n",
        "def loss_function(real, pred):\n",
        "    mask = tf.math.logical_not(tf.math.equal(real, 0))\n",
        "    loss_ = loss_object(real, pred)\n",
        "\n",
        "    mask = tf.cast(mask, dtype=loss_.dtype)\n",
        "    loss_ *= mask\n",
        "\n",
        "    return tf.reduce_mean(loss_)"
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fcxJ9Y56mxvv"
      },
      "source": [
        "checkpoint_dir = '/content/out/training_checkpoints'\n",
        "checkpoint_prefix = os.path.join(checkpoint_dir, \"ckpt\")\n",
        "checkpoint = tf.train.Checkpoint(optimizer=optimizer,\n",
        "                                 encoder=encoder,\n",
        "                                 decoder=decoder)"
      ],
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AJovMKqxmxta"
      },
      "source": [
        "@tf.function\n",
        "def train_step(inp, targ, enc_hidden):\n",
        "    loss = 0\n",
        "\n",
        "    with tf.GradientTape() as tape:\n",
        "        enc_output, enc_hidden = encoder(inp, enc_hidden)\n",
        "\n",
        "        dec_hidden = enc_hidden\n",
        "\n",
        "        dec_input = tf.expand_dims([lang_tokenizer[config.languages.target.name].word_index[config.preprocessing.start_token]] * config.model.batch_size, 1)\n",
        "\n",
        "        # Teacher forcing - feeding the target as the next input\n",
        "        for t in range(1, targ.shape[1]):\n",
        "        # passing enc_output to the decoder\n",
        "            predictions, dec_hidden, _ = decoder(dec_input, dec_hidden, enc_output)\n",
        "\n",
        "            loss += loss_function(targ[:, t], predictions)\n",
        "\n",
        "            # using teacher forcing\n",
        "            dec_input = tf.expand_dims(targ[:, t], 1)\n",
        "\n",
        "    batch_loss = (loss / int(targ.shape[1]))\n",
        "\n",
        "    variables = encoder.trainable_variables + decoder.trainable_variables\n",
        "\n",
        "    gradients = tape.gradient(loss, variables)\n",
        "\n",
        "    optimizer.apply_gradients(zip(gradients, variables))\n",
        "\n",
        "    return batch_loss"
      ],
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "90nMxDjN-DqI",
        "outputId": "bdbd1a8f-a9b7-40f2-e679-b16a0c14b0ef",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# Emperical estimate of time on colab for opus\n",
        "\n",
        "est_time = 0.02667*config.data.load_pcnt*config.training.epochs\n",
        "\n",
        "print(f'Estimated training time: {est_time:.2f} hrs.')"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Estimated training time: 0.53 hrs.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WybBwGZtna74",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1ca056f2-bad1-468d-f067-1262df5358be"
      },
      "source": [
        "for epoch in range(config.training.epochs):\n",
        "    start = time.time()\n",
        "\n",
        "    enc_hidden = encoder.initialize_hidden_state()\n",
        "    total_loss = 0\n",
        "\n",
        "    for (batch, (inp, targ)) in enumerate(dataset.take(steps_per_epoch)):       \n",
        "        batch_loss = train_step(inp, targ, enc_hidden)\n",
        "        total_loss += batch_loss\n",
        "\n",
        "        logger.log_scalar('batch_loss', batch_loss, step=batch)\n",
        "\n",
        "        if batch % 100 == 0:\n",
        "            print(f'Epoch {epoch+1} Batch {batch} Loss {batch_loss.numpy():.4f}')\n",
        "    \n",
        "    logger.log_scalar('total_loss', total_loss, step=epoch)\n",
        "    # saving (checkpoint) the model every 2 epochs\n",
        "    # if (epoch + 1) % 2 == 0:\n",
        "    checkpoint.save(file_prefix=checkpoint_prefix)\n",
        "\n",
        "    print(f'Epoch {epoch+1} Loss {total_loss/steps_per_epoch:.4f}')\n",
        "    print(f'Time taken for 1 epoch {time.time()-start:.2f} sec\\n')"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1 Batch 0 Loss 3.9530\n",
            "Epoch 1 Batch 100 Loss 2.5282\n",
            "Epoch 1 Batch 200 Loss 2.1872\n",
            "Epoch 1 Batch 300 Loss 1.8596\n",
            "Epoch 1 Batch 400 Loss 2.7386\n",
            "Epoch 1 Batch 500 Loss 2.0951\n",
            "Epoch 1 Batch 600 Loss 2.4958\n",
            "Epoch 1 Batch 700 Loss 1.6864\n",
            "Epoch 1 Batch 800 Loss 2.1364\n",
            "Epoch 1 Batch 900 Loss 1.8194\n",
            "Epoch 1 Batch 1000 Loss 0.9551\n",
            "Epoch 1 Batch 1100 Loss 1.9577\n",
            "Epoch 1 Batch 1200 Loss 1.5099\n",
            "Epoch 1 Batch 1300 Loss 1.8507\n",
            "Epoch 1 Batch 1400 Loss 1.4179\n",
            "Epoch 1 Batch 1500 Loss 1.4907\n",
            "Epoch 1 Batch 1600 Loss 1.2693\n",
            "Epoch 1 Batch 1700 Loss 1.7232\n",
            "Epoch 1 Batch 1800 Loss 1.3849\n",
            "Epoch 1 Batch 1900 Loss 1.4567\n",
            "Epoch 1 Batch 2000 Loss 1.7042\n",
            "Epoch 1 Batch 2100 Loss 1.4860\n",
            "Epoch 1 Batch 2200 Loss 1.0506\n",
            "Epoch 1 Batch 2300 Loss 1.7530\n",
            "Epoch 1 Batch 2400 Loss 1.3665\n",
            "Epoch 1 Batch 2500 Loss 1.2023\n",
            "Epoch 1 Batch 2600 Loss 1.4430\n",
            "Epoch 1 Batch 2700 Loss 1.3134\n",
            "Epoch 1 Batch 2800 Loss 1.1136\n",
            "Epoch 1 Batch 2900 Loss 0.8987\n",
            "Epoch 1 Batch 3000 Loss 1.2144\n",
            "Epoch 1 Batch 3100 Loss 0.7904\n",
            "Epoch 1 Batch 3200 Loss 0.9741\n",
            "Epoch 1 Batch 3300 Loss 1.2340\n",
            "Epoch 1 Batch 3400 Loss 1.2988\n",
            "Epoch 1 Batch 3500 Loss 1.1125\n",
            "Epoch 1 Batch 3600 Loss 1.3763\n",
            "Epoch 1 Batch 3700 Loss 0.7477\n",
            "Epoch 1 Batch 3800 Loss 1.2632\n",
            "Epoch 1 Batch 3900 Loss 1.5902\n",
            "Epoch 1 Batch 4000 Loss 1.6981\n",
            "Epoch 1 Batch 4100 Loss 1.1571\n",
            "Epoch 1 Batch 4200 Loss 1.2997\n",
            "Epoch 1 Batch 4300 Loss 0.8101\n",
            "Epoch 1 Batch 4400 Loss 0.9977\n",
            "Epoch 1 Batch 4500 Loss 1.2517\n",
            "Epoch 1 Batch 4600 Loss 0.8792\n",
            "Epoch 1 Batch 4700 Loss 1.3075\n",
            "Epoch 1 Batch 4800 Loss 1.1422\n",
            "Epoch 1 Batch 4900 Loss 0.9445\n",
            "Epoch 1 Batch 5000 Loss 0.9912\n",
            "Epoch 1 Batch 5100 Loss 1.2328\n",
            "Epoch 1 Batch 5200 Loss 1.0899\n",
            "Epoch 1 Batch 5300 Loss 1.0212\n",
            "Epoch 1 Batch 5400 Loss 0.8271\n",
            "Epoch 1 Batch 5500 Loss 1.2295\n",
            "Epoch 1 Batch 5600 Loss 0.9227\n",
            "Epoch 1 Batch 5700 Loss 1.1850\n",
            "Epoch 1 Batch 5800 Loss 0.9118\n",
            "Epoch 1 Batch 5900 Loss 1.4484\n",
            "Epoch 1 Batch 6000 Loss 0.7439\n",
            "Epoch 1 Batch 6100 Loss 0.5170\n",
            "Epoch 1 Batch 6200 Loss 0.9623\n",
            "Epoch 1 Batch 6300 Loss 0.7738\n",
            "Epoch 1 Batch 6400 Loss 0.9482\n",
            "Epoch 1 Batch 6500 Loss 0.6836\n",
            "Epoch 1 Batch 6600 Loss 0.6525\n",
            "Epoch 1 Batch 6700 Loss 0.8966\n",
            "Epoch 1 Batch 6800 Loss 0.8875\n",
            "Epoch 1 Batch 6900 Loss 1.0643\n",
            "Epoch 1 Loss 1.2952\n",
            "Time taken for 1 epoch 3053.55 sec\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k9bPFVrZXLud"
      },
      "source": [
        "def evaluate(sentence):\n",
        "    attention_plot = np.zeros((max_len_targ, max_len_inp))\n",
        "\n",
        "    sentence = preprocess_sentence(sentence, config.languages.input.sentence_maxlen)\n",
        "    oov_index = lang_tokenizer[config.languages.input.name].word_index[config.preprocessing.oov_token]\n",
        "    inputs = [lang_tokenizer[config.languages.input.name].word_index.get(i, oov_index) for i in sentence.split(' ')]\n",
        "    inputs = tf.keras.preprocessing.sequence.pad_sequences([inputs],\n",
        "                                                            maxlen=max_len_inp,\n",
        "                                                            padding=config.preprocessing.padding)\n",
        "    inputs = tf.convert_to_tensor(inputs)\n",
        "\n",
        "    result = ''\n",
        "\n",
        "    hidden = [tf.zeros((1, config.model.n_units))]\n",
        "    enc_out, enc_hidden = encoder(inputs, hidden)\n",
        "\n",
        "    dec_hidden = enc_hidden\n",
        "    dec_input = tf.expand_dims([lang_tokenizer[config.languages.target.name].word_index[config.preprocessing.start_token]], 0)\n",
        "\n",
        "    for t in range(max_len_targ):\n",
        "        predictions, dec_hidden, attention_weights = decoder(dec_input,\n",
        "                                                            dec_hidden,\n",
        "                                                            enc_out)\n",
        "\n",
        "        # storing the attention weights to plot later on\n",
        "        attention_weights = tf.reshape(attention_weights, (-1, ))\n",
        "        attention_plot[t] = attention_weights.numpy()\n",
        "\n",
        "        predicted_id = tf.argmax(predictions[0]).numpy() # Greedy\n",
        "\n",
        "        result += lang_tokenizer[config.languages.target.name].index_word[predicted_id] + ' '\n",
        "\n",
        "        if lang_tokenizer[config.languages.target.name].index_word[predicted_id] == config.preprocessing.end_token:\n",
        "            return result, sentence, attention_plot\n",
        "\n",
        "        # the predicted ID is fed back into the model\n",
        "        dec_input = tf.expand_dims([predicted_id], 0)\n",
        "\n",
        "    return result, sentence, attention_plot"
      ],
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-zZs-2K1QIZD"
      },
      "source": [
        "def plot_attention(attention, sentence, predicted_sentence):\n",
        "    fig = plt.figure(figsize=(10, 10))\n",
        "    ax = fig.add_subplot(1, 1, 1)\n",
        "    ax.matshow(attention, cmap='gray')\n",
        "\n",
        "    fontdict = {'fontsize': 14}\n",
        "\n",
        "    ax.set_xticklabels([''] + sentence, fontdict=fontdict, rotation=90)\n",
        "    ax.set_yticklabels([''] + predicted_sentence, fontdict=fontdict)\n",
        "\n",
        "    ax.xaxis.set_major_locator(ticker.MultipleLocator(1))\n",
        "    ax.yaxis.set_major_locator(ticker.MultipleLocator(1))\n",
        "\n",
        "    plt.show()"
      ],
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jkgAftxGQaHX"
      },
      "source": [
        "def translate(sentence):\n",
        "    if type(sentence)==str:\n",
        "        sentence = sentence.encode()\n",
        "    result, sentence, attention_plot = evaluate(sentence)\n",
        "\n",
        "    print('Input:', sentence)\n",
        "    print('Predicted translation:', result)\n",
        "\n",
        "    attention_plot = attention_plot[:len(result.split(' ')),\n",
        "                                    :len(sentence.split(' '))]\n",
        "    plot_attention(attention_plot, sentence.split(' '), result.split(' '))"
      ],
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "njUP-0V7qsDL",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 550
        },
        "outputId": "b20302a9-557a-4b2a-9ae5-ebaf89193c1b"
      },
      "source": [
        "translate('There are no known side effects')"
      ],
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Input: <start> there are no known side effects <end>\n",
            "Predicted translation: es gibt keine bekannt <end> \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 720x720 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iPH9lXINNXi3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "49a9dabb-3daf-488c-f662-53b4bf3b6076"
      },
      "source": [
        "!tensorboard dev upload --logdir {config.logging.dir} \\\n",
        "  --name \"{config.logging.name}\" \\\n",
        "  --description \"{config.logging.description}\" \\\n",
        "  --one_shot"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2021-05-21 18:53:18.210675: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0\n",
            "\n",
            "***** TensorBoard Uploader *****\n",
            "\n",
            "This will upload your TensorBoard logs to https://tensorboard.dev/ from\n",
            "the following directory:\n",
            "\n",
            "/content/out/tensorboard/logs/\n",
            "\n",
            "This TensorBoard will be visible to everyone. Do not upload sensitive\n",
            "data.\n",
            "\n",
            "Your use of this service is subject to Google's Terms of Service\n",
            "<https://policies.google.com/terms> and Privacy Policy\n",
            "<https://policies.google.com/privacy>, and TensorBoard.dev's Terms of Service\n",
            "<https://tensorboard.dev/policy/terms/>.\n",
            "\n",
            "This notice will not be shown again while you are logged into the uploader.\n",
            "To log out, run `tensorboard dev auth revoke`.\n",
            "\n",
            "Continue? (yes/NO) yes\n",
            "\n",
            "Please visit this URL to authorize this application: https://accounts.google.com/o/oauth2/auth?response_type=code&client_id=373649185512-8v619h5kft38l4456nm2dj4ubeqsrvh6.apps.googleusercontent.com&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&scope=openid+https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fuserinfo.email&state=ffbirKwtzMVsprcln0FwDE4I8sBKIz&prompt=consent&access_type=offline\n",
            "Enter the authorization code: 4/1AY0e-g46OWyrGYVbaKpGoEincurQxdq9Mip8FuvOmp8PpzPLpiEE2zoOXpE\n",
            "\n",
            "Data for the \"text\" plugin is now uploaded to TensorBoard.dev! Note that uploaded data is public. If you do not want to upload data for this plugin, use the \"--plugins\" command line argument.\n",
            "\n",
            "New experiment created. View your TensorBoard at: https://tensorboard.dev/experiment/HE3oY2ReS0S6ZzC5Has2vw/\n",
            "\n",
            "\u001b[1m[2021-05-21T18:54:16]\u001b[0m Started scanning logdir.\n",
            "\u001b[1m[2021-05-21T18:54:19]\u001b[0m Total uploaded: 10582 scalars, 0 tensors, 0 binary objects\n",
            "\u001b[1m[2021-05-21T18:54:19]\u001b[0m Done scanning logdir.\n",
            "\n",
            "\n",
            "Done. View your TensorBoard at https://tensorboard.dev/experiment/HE3oY2ReS0S6ZzC5Has2vw/\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wy-iP6IyNXhB",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "0145b36e-6573-40ed-c7ff-310451f519c1"
      },
      "source": [
        "config.logging.dir"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'/content/out/tensorboard/logs/'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vL_P0clCNXe4"
      },
      "source": [
        "data_src_1 = '/content/out/training_checkpoints/ckpt-1.data-00000-of-00001'\n",
        "data_dest_1 = '/content/drive/MyDrive/Colab Notebooks/Data/seq2seqcheckpoints/ckpt-1.data-00000-of-00001'\n",
        "\n",
        "data_src_2 = '/content/out/training_checkpoints/ckpt-1.index'\n",
        "data_dest_2 = '/content/drive/MyDrive/Colab Notebooks/Data/seq2seqcheckpoints/ckpt-1.index'"
      ],
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "StamxXA-NXcg"
      },
      "source": [
        "d = shutil.copyfile(data_src_2, data_dest_2)"
      ],
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1csevuB96KRL"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}